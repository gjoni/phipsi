{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of CPUs to be used\n",
    "NCPU=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json\n",
    "import numpy as np\n",
    "import utils \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 20 standard amino acids\n",
    "aa2idx = {'A':0, 'R':1, 'N':2, 'D':3, 'C':4, 'Q':5, 'E':6, 'G':7, 'H':8, 'I':9,\n",
    "          'L':10, 'K':11, 'M':12, 'F':13, 'P':14, 'S':15, 'T':16, 'W':17, 'Y':18, 'V':19}\n",
    "\n",
    "# load\n",
    "dataset = utils.load_phipsi()\n",
    "\n",
    "# 90% train, 10% test\n",
    "train,test = train_test_split(dataset, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomness in clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering is not guarantied to converge to the best  global solution each time you run it, but rather gives you a local suboptimal splitting. To check how this randomness in the k-means clusters affects the full angle prediction pipeline, we repeat clustering-training-testing procedure multiple times (number of clusters is fixed to 15) and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 15\n",
    "\n",
    "# do not need to change X (1-hot-encoded sequence)\n",
    "# so can set it only once\n",
    "X_train = utils.getX(train, WINDOW)\n",
    "X_test = utils.getX(test, WINDOW)\n",
    "\n",
    "# reference phi,psi for the test set\n",
    "# also do not change\n",
    "phi_ref = utils.getPHI(test, WINDOW)\n",
    "psi_ref = utils.getPSI(test, WINDOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "WINDOW = 15\n",
    "\n",
    "# number of times clustering-learning-testing pipeline\n",
    "# will be repeated\n",
    "niter = 15\n",
    "\n",
    "# save all clustering results here\n",
    "KMEANS = []\n",
    "scores1 = []\n",
    "\n",
    "for i in range(niter):\n",
    "    \n",
    "    # cluster\n",
    "    KM = KMeans(n_clusters=20, max_iter=5, n_jobs=NCPU)\n",
    "    KM.fit(np.vstack([item['avec'] for item in train]))\n",
    "    \n",
    "    # save current solution\n",
    "    KMEANS.append(KM)\n",
    "    \n",
    "    # update Y vectors (cluster IDs for central residues)\n",
    "    Y_train = utils.getY(train, WINDOW, KM)\n",
    "    Y_test = utils.getY(test, WINDOW, KM)\n",
    "    \n",
    "    # train logistis regression model\n",
    "    sgd = SGDClassifier(max_iter=10, tol=1e-3, loss='log', n_jobs=NCPU)\n",
    "    sgd.fit(X_train, Y_train)\n",
    "    \n",
    "    # calculate sin(.),cos(.) weighted averages on the test set\n",
    "    avec = np.matmul(sgd.predict_proba(X_test), KM.cluster_centers_)\n",
    "\n",
    "    # convert angle vectors to true angles\n",
    "    norm_phi = np.sqrt(np.square(avec[:,0])+np.square(avec[:,1]))\n",
    "    norm_psi = np.sqrt(np.square(avec[:,2])+np.square(avec[:,3]))\n",
    "    phi_pred = np.arctan2(avec[:,0] / norm_phi, avec[:,1] / norm_phi)\n",
    "    psi_pred = np.arctan2(avec[:,2] / norm_psi, avec[:,3] / norm_psi)\n",
    "\n",
    "    # calculate scores\n",
    "    loss = log_loss(Y_test, sgd.predict_proba(X_test))\n",
    "    rmse_phi = utils.ang_rmse(phi_ref, phi_pred) * 180 / np.pi\n",
    "    rmse_psi = utils.ang_rmse(psi_ref, psi_pred) * 180 / np.pi\n",
    "    \n",
    "    scores1.append([rmse_phi, rmse_psi, loss])\n",
    "    \n",
    "    print(\"iter {:2d} | loss {:.5f} | rmse(phi) {:9.5f} | rmse(phi) {:9.5f}\".\n",
    "          format(i, loss, rmse_phi, rmse_psi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "xyc = np.array(scores1)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.xlabel('rmse(phi)', fontsize=15)\n",
    "plt.ylabel('rmse(psi)', fontsize=15)\n",
    "plt.grid()\n",
    "plt.rc('axes', axisbelow=True)\n",
    "plt.title('Variation in accuracy', fontsize=20)\n",
    "plt.scatter(xyc[:,0], xyc[:,1], c=xyc[:,2], s=100)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first cluster\n",
    "KM = KMEANS[0]\n",
    "\n",
    "scores2 = []\n",
    "\n",
    "for WINDOW in range(1,32,2):\n",
    "    \n",
    "    # WINDOW changes, so does X\n",
    "    X_train = utils.getX(train, WINDOW)\n",
    "    X_test = utils.getX(test, WINDOW)\n",
    "    \n",
    "    # update Y vectors (cluster IDs for central residues)\n",
    "    Y_train = utils.getY(train, WINDOW, KM)\n",
    "    Y_test = utils.getY(test, WINDOW, KM)\n",
    "    \n",
    "    # same for reference angles\n",
    "    phi_ref = utils.getPHI(test, WINDOW)\n",
    "    psi_ref = utils.getPSI(test, WINDOW)\n",
    "\n",
    "    # train logistis regression model\n",
    "    sgd = SGDClassifier(max_iter=10, tol=1e-3, loss='log', n_jobs=NCPU)\n",
    "    sgd.fit(X_train, Y_train)\n",
    "    \n",
    "    # calculate sin(.),cos(.) weighted averages on the test set\n",
    "    avec = np.matmul(sgd.predict_proba(X_test), KM.cluster_centers_)\n",
    "\n",
    "    # convert angle vectors to true angles\n",
    "    norm_phi = np.sqrt(np.square(avec[:,0])+np.square(avec[:,1]))\n",
    "    norm_psi = np.sqrt(np.square(avec[:,2])+np.square(avec[:,3]))\n",
    "    phi_pred = np.arctan2(avec[:,0] / norm_phi, avec[:,1] / norm_phi)\n",
    "    psi_pred = np.arctan2(avec[:,2] / norm_psi, avec[:,3] / norm_psi)\n",
    "\n",
    "    # calculate scores\n",
    "    loss = log_loss(Y_test, sgd.predict_proba(X_test))\n",
    "    rmse_phi = utils.ang_rmse(phi_ref, phi_pred) * 180 / np.pi\n",
    "    rmse_psi = utils.ang_rmse(psi_ref, psi_pred) * 180 / np.pi\n",
    "    \n",
    "    scores2.append([WINDOW, rmse_phi, rmse_psi, loss])\n",
    "    \n",
    "    print(\"WINDOW {:2d} | loss {:.5f} | rmse(phi) {:9.5f} | rmse(phi) {:9.5f}\".\n",
    "          format(WINDOW, loss, rmse_phi, rmse_psi))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "fig.set_size_inches(15, 4)\n",
    "\n",
    "xyc = np.array(scores2)\n",
    "\n",
    "# set style\n",
    "for col in (0,1,2):\n",
    "    ax[col].set_xlim([0,32])\n",
    "    ax[col].set_xlabel(\"window size\", fontsize=15)\n",
    "\n",
    "ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "ax[0].plot(xyc[:,0], xyc[:,3], linestyle='-', marker='o', color='g')\n",
    "\n",
    "ax[1].set_ylabel(\"rmse(phi)\", fontsize=15)\n",
    "ax[1].plot(xyc[:,0], xyc[:,1], linestyle='-', marker='o', color='g')\n",
    "\n",
    "ax[2].set_ylabel(\"rmse(psi)\", fontsize=15)\n",
    "ax[2].plot(xyc[:,0], xyc[:,2], linestyle='-', marker='o', color='g')\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
