{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of CPUs to be used\n",
    "NCPU=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, gzip\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "aa2idx = {'A':0, 'R':1, 'N':2, 'D':3, 'C':4, 'Q':5, 'E':6, 'G':7, 'H':8, 'I':9,\n",
    "          'L':10, 'K':11, 'M':12, 'F':13, 'P':14, 'S':15, 'T':16, 'W':17, 'Y':18, 'V':19}\n",
    "\n",
    "# read .json file\n",
    "with gzip.open('../data/phipsi.json.gz', 'rb') as f:\n",
    "    dataset = json.loads(f.read().decode('utf-8'))\n",
    "\n",
    "# reduse dataset to a list for simpler access\n",
    "dataset = dataset['phipsi10882']\n",
    "\n",
    "# convert data to numpy arrays skipping first and last residues\n",
    "for item in dataset:\n",
    "    n = len(item['sequence'])\n",
    "    item['sequence'] = np.array([aa2idx[aa] for aa in item['sequence'][1:n-1]], dtype=np.int8)\n",
    "    item['phi'] = np.array(item['phi'], dtype=np.float32)[1:n-1]\n",
    "    item['psi'] = np.array(item['psi'], dtype=np.float32)[1:n-1]\n",
    "    \n",
    "    # convert (phi,psi) to their sin() and cos()\n",
    "    # (4 numbers per angle pair)\n",
    "    item['avec'] = np.vstack([\n",
    "        np.sin(item['phi']).T,\n",
    "        np.cos(item['phi']).T,\n",
    "        np.sin(item['psi']).T,\n",
    "        np.cos(item['psi']).T ]).T\n",
    "\n",
    "# 90% train, 10% test\n",
    "train,test = train_test_split(dataset, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.9 s, sys: 47.2 s, total: 1min 42s\n",
      "Wall time: 43.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# split train set into 20 clusters\n",
    "KMEANS = KMeans(n_clusters=20, max_iter=5, n_jobs=NCPU)\n",
    "KMEANS.fit(np.vstack([item['avec'] for item in train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Help functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign each (phi,psi) to a cluster\n",
    "# (KMEANS stores clustering results)\n",
    "def set_clusters(train, test, KMEANS):\n",
    "    for subset in (train, test):\n",
    "        for item in subset:\n",
    "            item['abin'] = np.array(KMEANS.predict(item['avec']), dtype=np.int8)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split all sequences into chunks of size WINDOW\n",
    "def set_window(train, test, WINDOW):\n",
    "    \n",
    "    for subset in (train, test):\n",
    "        for item in subset:\n",
    "            l = len(item['sequence'])\n",
    "\n",
    "            abin = item['abin']\n",
    "            seq = item['sequence']\n",
    "\n",
    "            # for every window, pick the element in the middle and\n",
    "            # save corresponding dihedral cluster ID in item['Y']\n",
    "            item['Y'] = np.hstack([item[WINDOW//2] \n",
    "                                   for shift in range(0,WINDOW,1) \n",
    "                                   for item in np.split(abin[shift:],range(0,l,WINDOW)) \n",
    "                                   if len(item) == WINDOW])\n",
    "\n",
    "            # use 1-hot encoding for every sequence chunk\n",
    "            seq_chunks = np.vstack([item for shift in range(0,WINDOW,1) \n",
    "                                    for item in np.split(seq[shift:],range(0,l,WINDOW)) \n",
    "                                    if len(item) == WINDOW])\n",
    "            item['X'] = np.array(np.eye(20)[seq_chunks], dtype=np.int8).reshape((seq_chunks.shape[0],-1))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.27731598535191937 0.27676418816894827 2.374077414593405\n",
      "3 0.291750679077452 0.29088582445151623 2.275495572812937\n",
      "5 0.3029658723360613 0.30326357557373845 2.2337286323513728\n",
      "7 0.310950939033964 0.3112886350382491 2.2092355370879977\n",
      "9 0.3155080990072185 0.3161927022464615 2.1956344308986053\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "set_clusters(train, test, KMEANS)\n",
    "\n",
    "for WINDOW in range(1,33,2):\n",
    "    set_window(train, test, WINDOW)\n",
    "    \n",
    "    X_train = np.vstack([item['X'] for item in train])\n",
    "    Y_train = np.hstack([item['Y'] for item in train])\n",
    "    X_test = np.vstack([item['X'] for item in test])\n",
    "    Y_test = np.hstack([item['Y'] for item in test])\n",
    "    \n",
    "    sgd = SGDClassifier(max_iter=10, tol=1e-3, loss='log', n_jobs=NCPU)\n",
    "    sgd.fit(X_train, Y_train)\n",
    "    \n",
    "    score_train = sgd.score(X_train, Y_train)\n",
    "    score_test = sgd.score(X_test, Y_test)\n",
    "    \n",
    "    loss = log_loss(Y_test, sgd.predict_proba(X_test))\n",
    "\n",
    "    print(WINDOW, score_train, score_test, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization strength tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#params = {'l1_ratio' : np.linspace(0.0, 1.0, 11), 'alpha' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1] }\n",
    "params = {'l1_ratio' : np.linspace(0.0, 1.0, 11)}\n",
    "\n",
    "X_train = np.vstack([item['X'] for item in train[::10]])\n",
    "Y_train = np.hstack([item['Y'] for item in train[::10]])\n",
    "\n",
    "sgd = SGDClassifier(max_iter=100, tol=1e-3, loss='log', n_jobs=4)\n",
    "hsearch = GridSearchCV(sgd, params, cv=5, verbose=2, n_jobs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hsearch.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for mean, std, params in zip(means, stds, hsearch.cv_results_['params']):\n",
    "       print(\"%0.5f (+/-%0.05f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
