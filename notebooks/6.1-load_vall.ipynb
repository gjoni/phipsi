{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import scipy\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import signal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vall size:  16800\n",
      "CPU times: user 4.81 s, sys: 439 ms, total: 5.25 s\n",
      "Wall time: 5.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with gzip.GzipFile('../data/vall.jul19.2011.json.gz', 'r') as fin:\n",
    "    json_bytes = fin.read() \n",
    "\n",
    "json_str = json_bytes.decode('utf-8')\n",
    "vall = json.loads(json_str)\n",
    "print(\"vall size: \", len(vall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load kmeans clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 ms, sys: 19.4 ms, total: 21 ms\n",
      "Wall time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('../data/phipsi_km20.pkl', 'rb') as f:\n",
    "    KM = pickle.load(f)\n",
    "    \n",
    "NCLUST = KM.cluster_centers_.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign clusters to (&phi;,&psi;) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 698 ms, total: 16.5 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key,item in vall.items():\n",
    "    n = len(item['seq'])\n",
    "    phi = np.array(item['phi'], dtype=np.float16)\n",
    "    psi = np.array(item['psi'], dtype=np.float16)\n",
    "    avec = np.vstack([np.sin(phi).T, np.cos(phi).T, np.sin(psi).T, np.cos(psi).T ]).T\n",
    "    item['abin'] = np.eye(NCLUST)[KM.predict(avec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one of the vall 'profiles'\n",
    "vall['7odcA']['abin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generated 'profile'\n",
    "L = 200\n",
    "query = np.random.rand(L, NCLUST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 1)\n",
      "CPU times: user 4.75 s, sys: 76 ms, total: 4.83 s\n",
      "Wall time: 4.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hits = {}\n",
    "\n",
    "# search vall for one fragment\n",
    "chunk = query[0:9,:]\n",
    "for key,item in vall.items():\n",
    "    hits[key] = signal.correlate2d(item['abin'], chunk, mode='valid')\n",
    "\n",
    "print(hits['7odcA'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2boyA\n",
      "2000 3civA\n",
      "3000 1kz1A\n",
      "4000 3hygA\n",
      "5000 1nezG\n",
      "6000 2fupA\n",
      "7000 2cioA\n",
      "8000 3m5wA\n",
      "9000 2pbnA\n",
      "10000 1xu2R\n",
      "11000 1u46A\n",
      "12000 3pqkA\n",
      "13000 3h0nA\n",
      "14000 1tuwA\n",
      "15000 3ofgA\n",
      "16000 1fyeA\n",
      "CPU times: user 2min 34s, sys: 595 ms, total: 2min 35s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# search for 9-mers\n",
    "WINDOW = 9\n",
    "\n",
    "hits = {}\n",
    "\n",
    "iter=0\n",
    "for key,item in vall.items():\n",
    "    iter += 1\n",
    "    \n",
    "    # print every 1000\n",
    "    if iter%1000==0:\n",
    "        print(iter, key)\n",
    "    \n",
    "    # correlate all fragments of the query\n",
    "    hits[key] = np.hstack([signal.correlate2d(item['abin'], query[shift:shift+WINDOW,:], mode='valid') \n",
    "               for shift in range(L - WINDOW + 1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(379, 92)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits['7odcA'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superfast ```tensorflow``` search which takes ~1s to scan through entire VALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built with GPU: True\n",
      "GPU available: True\n",
      "GPU device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Built with GPU:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())\n",
    "print(\"GPU device:\", tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4126307, 20, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vall_vec = np.vstack([item['abin'] for _,item in vall.items()])\n",
    "vall_in = np.reshape(vall_vec, (1,vall_vec.shape[0],20,1))\n",
    "vall_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 9\n",
    "tmp = np.stack([query[shift:shift+WINDOW,:] for shift in range(L - WINDOW + 1)])\n",
    "filter = np.reshape(np.transpose(tmp, axes=[1,2,0]), (9,20,1,192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "978 ms ± 19.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "i = tf.placeholder(tf.float32, (1, 4126307, 20, 1))\n",
    "f = tf.placeholder(tf.float32, (9,20,1,192))\n",
    "o = tf.nn.conv2d(input=i, filter=f, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    out = sess.run(o, feed_dict={i : vall_in, f : filter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py-2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
